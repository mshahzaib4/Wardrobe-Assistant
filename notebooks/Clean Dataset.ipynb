{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfa599",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "09b48c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurti = pd.read_csv(\"../data/Dataset Files/Lang_Chain-kurti.csv\")\n",
    "kurti = kurti.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "96f66c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kurti.drop(columns=[\"Package Content\", \"package_contents\"], inplace= True)\n",
    "kurti[\"package_contents\"] = \"Kurti\"\n",
    "kurti[\"Gender\"] = \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "253460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_outfit(name):\n",
    "    name_lower = name.lower()\n",
    "\n",
    "    # Priority-based categories\n",
    "    if 'sherwani' in name_lower:\n",
    "        return 'Sherwani'\n",
    "    elif 'angrakha' in name_lower:\n",
    "        return 'Angrakha'\n",
    "    elif 'jodhpuri' in name_lower or 'coat pant' in name_lower:\n",
    "        return 'Jodhpuri Suit'\n",
    "    elif 'pathani' in name_lower or 'pathan' in name_lower:\n",
    "        return 'Pathani Suit'\n",
    "    elif 'indo-western' in name_lower:\n",
    "        return 'Indo-Western'\n",
    "    elif 'achkan' in name_lower:\n",
    "        return 'Achkan'\n",
    "    elif 'waist coat' in name_lower or 'waistcoat' in name_lower:\n",
    "        return 'Waistcoat'\n",
    "    elif 'tuxedo' in name_lower:\n",
    "        return 'Tuxedo Suit'\n",
    "    elif 'blazer' in name_lower:\n",
    "        return 'Blazer Suit'\n",
    "    elif 'jacket style' in name_lower:\n",
    "        return 'Jacket Style Outfit'\n",
    "    elif 'nehru jacket' in name_lower or 'jacket' in name_lower:\n",
    "        return 'Nehru Jacket'\n",
    "    elif 'gown' in name_lower:\n",
    "        return 'Gown'\n",
    "    elif 'lehenga' in name_lower:\n",
    "        return 'Lehenga'\n",
    "    elif 'saree' in name_lower:\n",
    "        return 'Saree'\n",
    "    elif 'kurti' in name_lower:\n",
    "        return 'Kurti'\n",
    "    elif 'anarkali' in name_lower:\n",
    "        return 'Anarkali Suit'\n",
    "    elif 'trouser suit' in name_lower or 'trouser pant' in name_lower:\n",
    "        return 'Trouser Suit'\n",
    "    elif 'dhoti pant' in name_lower:\n",
    "        return 'Indo Western Dhoti Set'\n",
    "    elif 'dhoti' in name_lower:\n",
    "        return 'Kurta with Dhoti'\n",
    "    elif 'sharara' in name_lower:\n",
    "        return 'Sharara Suit'\n",
    "    elif 'palazzo' in name_lower:\n",
    "        return 'Palazzo Suit'\n",
    "    elif 'churidar' in name_lower:\n",
    "        return 'Churidar Suit'\n",
    "    elif 'patiala' in name_lower:\n",
    "        return 'Patiala Suit'\n",
    "    elif 'cigarette pant' in name_lower:\n",
    "        return 'Cigarette Pant Suit'\n",
    "    elif 'straight pant' in name_lower or 'pant suit' in name_lower:\n",
    "        return 'Pant Suit'\n",
    "    elif 'salwar kameez' in name_lower:\n",
    "        return 'Salwar Kameez'\n",
    "    elif 'salwar' in name_lower:\n",
    "        return 'Salwar Suit'\n",
    "    elif 'kurta' in name_lower:\n",
    "        if any(x in name_lower for x in ['pajama', 'salwar', 'churidar', 'trouser', 'pant']):\n",
    "            return 'Kurta Set'\n",
    "        else:\n",
    "            return 'Kurta'\n",
    "    elif 'suit' in name_lower:\n",
    "        return 'General Suit'\n",
    "    else:\n",
    "        return 'Uncategorized'\n",
    "    \n",
    "kurti['categorize_outfit'] = kurti['product_name'].apply(categorize_outfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7dd49d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(work):\n",
    "    if not isinstance(work, str):\n",
    "        return \"Others\"\n",
    "\n",
    "    if any(x in work for x in [\"Printed\", \"Print\", \"Foil\"]):\n",
    "        return \"Printed & Foil Work\"\n",
    "    elif any(x in work for x in [\"Resham Work\", \"Thread Work\", \"Weaved\", \"Woven\", \"Zari\", \"Zardosi\"]):\n",
    "        return \"Thread & Resham Work\"\n",
    "    elif any(x in work for x in [\"Beads Work\", \"Cutdana Work\", \"Stone Work\", \"Pearl Work\"]):\n",
    "        return \"Beads, Cutdana & Stone Work\"\n",
    "    elif any(x in work for x in [\"Gota Patti\", \"Lace\"]):\n",
    "        return \"Gota Patti & Lace Work\"\n",
    "    elif any(x in work for x in [\"Plain\", \"Embroidered\", \"Embroidery\", \"Top (Included Lining)\", \"Sequins\"]):\n",
    "        return \"Others\"\n",
    "    else:\n",
    "        return \"Others\"\n",
    "kurti['work_details'] = kurti['work_details'].apply(categorize)\n",
    "kurti[\"work_details\"] = kurti[\"work_details\"].replace(\"Others\", \"Printed & Foil Work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e74815cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cotton_based = ['Cotton', 'Cotton Slub', 'Cotton Rayon', 'Cotton slub', 'Cotton Blended']\n",
    "silk_based = ['Silk', 'Chanderi Silk', 'Dupion Silk', 'Bamberg Silk', 'Chinnon', 'Muslin', 'Chanderi', 'Organza']\n",
    "synthetic = ['Rayon', 'Poly Crepe', 'Crepe', 'Georgette', 'Moss Georgette', 'Satin', 'Net']\n",
    "\n",
    "# Function to categorize\n",
    "def categorize_fabric(fabric):\n",
    "    if fabric in cotton_based:\n",
    "        return 'Cotton-based'\n",
    "    elif fabric in silk_based:\n",
    "        return 'Silk-based'\n",
    "    elif fabric in synthetic:\n",
    "        return 'Synthetic'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# Apply categorization\n",
    "kurti['fabric_top'] = kurti['fabric_top'].apply(categorize_fabric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "21e9be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cotton_based = ['Cotton', 'Cotton Slub', 'Cotton Rayon', 'Cotton slub', 'Cotton Blended']\n",
    "silk_based = ['Silk', 'Chanderi Silk', 'Dupion Silk', 'Bamberg Silk', 'Chinnon', 'Muslin', 'Chanderi', 'Organza']\n",
    "synthetic = ['Rayon', 'Poly Crepe', 'Crepe', 'Georgette', 'Moss Georgette', 'Satin', 'Net']\n",
    "\n",
    "# Categorization function\n",
    "def categorize_fabric(fabric):\n",
    "    if fabric in cotton_based:\n",
    "        return 'Cotton-based'\n",
    "    elif fabric in silk_based:\n",
    "        return 'Silk-based'\n",
    "    elif fabric in synthetic:\n",
    "        return 'Synthetic'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# Apply the function to categorize fabric_bottom\n",
    "kurti['fabric_bottom'] = kurti['fabric_bottom'].apply(categorize_fabric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e40d248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurti.loc[kurti[\"product_type\"] == \"Kurti Tunic\", \"product_type\"] = \"Kurti\"\n",
    "kurti.loc[kurti[\"product_type\"] == \"Anarkali\", \"product_type\"] = \"Kurti\"\n",
    "kurti.loc[kurti[\"style\"] == \"Unknown\", \"style\"] = None\n",
    "kurti.drop(columns=[\"Unnamed: 0\", \"web-scraper-order\", \"fabric_bottom\", \"package_contents\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "18a1e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_work(work):\n",
    "    work = work.lower()\n",
    "    if \"print\" in work or \"foil\" in work:\n",
    "        return \"Printed Work\"\n",
    "    elif \"thread\" in work or \"resham\" in work or \"gota\" in work or \"lace\" in work:\n",
    "        return \"Embroidery Work\"\n",
    "    elif \"beads\" in work or \"cutdana\" in work or \"stone\" in work:\n",
    "        return \"Embellished Work\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "kurti['work_details'] = kurti['work_details'].apply(categorize_work)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef2791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_occasion(occasion):\n",
    "    if not isinstance(occasion, str):\n",
    "        return \"Unknown\"\n",
    "    occasion = str(occasion).lower()\n",
    "    \n",
    "    if \"wedding\" in occasion or \"sangeet\" in occasion:\n",
    "        return \"Wedding/Formal\"\n",
    "    elif \"party\" in occasion or \"festive\" in occasion or \"festival\" in occasion:\n",
    "        return \"Party/Festive\"\n",
    "    elif \"casual\" in occasion or \"daily\" in occasion or \"office\" in occasion or \"semi-formal\" in occasion or \"formal\" in occasion:\n",
    "        return \"Casual\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "kurti['occasion'] = kurti['occasion'].apply(categorize_occasion)\n",
    "kurti.loc[kurti[\"occasion\"]==\"Unknown\", \"occasion\"] = \"Party/Festive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d709d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_season(row):\n",
    "    fabric = str(row['fabric_top']).lower()\n",
    "    color = str(row['color']).lower()\n",
    "    occasion = str(row['occasion']).lower()\n",
    "    style = str(row['style']).lower()\n",
    "    product = str(row['product_type']).lower()\n",
    "\n",
    "    # --- Summer ---\n",
    "    if any(x in fabric for x in ['cotton', 'chiffon', 'linen']) or \\\n",
    "       any(x in color for x in ['yellow', 'pink', 'white', 'peach', 'light']) or \\\n",
    "       any(x in style for x in ['sleeveless', 'printed', 'light']) or \\\n",
    "       any(x in occasion for x in ['beach', 'casual']) or \\\n",
    "       any(x in product for x in ['kurti', 'tunic', 'saree']):\n",
    "        return 'Summer'\n",
    "\n",
    "    # --- Winter ---\n",
    "    elif any(x in fabric for x in ['wool', 'velvet', 'fleece', 'pashmina']) or \\\n",
    "         any(x in color for x in ['black', 'navy', 'dark', 'maroon']) or \\\n",
    "         any(x in style for x in ['heavy', 'layered']) or \\\n",
    "         any(x in product for x in ['coat', 'sweater', 'sherwani']):\n",
    "        return 'Winter'\n",
    "\n",
    "    # --- Fall/Autumn ---\n",
    "    elif any(x in color for x in ['brown', 'rust', 'olive']) or \\\n",
    "         any(x in occasion for x in ['office', 'semi-formal']):\n",
    "        return 'Autumn'\n",
    "\n",
    "    # --- Spring ---\n",
    "    elif any(x in color for x in ['floral', 'green', 'blue']) or \\\n",
    "         any(x in occasion for x in ['festival', 'party']) or \\\n",
    "         any(x in style for x in ['floral']):\n",
    "        return 'Spring'\n",
    "\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d474d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurti['season'] = kurti.apply(infer_season, axis=1)\n",
    "kurti['main_category'] = kurti['main_category'].replace('Women', 'Women\\'s Ethnic Wear')\n",
    "kurti.drop(columns=[\"worn_by\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a01aa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_fit_columns(val):\n",
    "    val = str(val).strip().lower()\n",
    "    \n",
    "    if 'one size' in val:\n",
    "        return pd.Series(['Free Size', 'Free Size'])\n",
    "    \n",
    "    if 'not specified' in val or val == 'nan':\n",
    "        return pd.Series(['Unknown', 'Unknown'])\n",
    "\n",
    "    # Extract numbers\n",
    "    numbers = list(map(int, re.findall(r'\\d+', val)))\n",
    "\n",
    "    # Determine fit type\n",
    "    if '-' in val and ',' in val:\n",
    "        fit_type = 'Mixed Range'\n",
    "    elif '-' in val:\n",
    "        fit_type = 'Range'\n",
    "    elif ',' in val:\n",
    "        fit_type = 'Multi Size'\n",
    "    elif len(numbers) == 1:\n",
    "        fit_type = 'Single Size'\n",
    "    else:\n",
    "        fit_type = 'Unknown'\n",
    "\n",
    "    # Format size_range\n",
    "    if numbers:\n",
    "        size_range = f\"{min(numbers)}–{max(numbers)}\"\n",
    "    else:\n",
    "        size_range = 'Unknown'\n",
    "\n",
    "    return pd.Series([fit_type, size_range])\n",
    "\n",
    "# Apply function\n",
    "kurti[['fit_type', 'size_range']] = kurti['fit'].apply(extract_fit_columns)\n",
    "kurti.drop(columns=\"fit\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "69ca62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurti = kurti.replace(\"Unknown\", None)\n",
    "kurti = kurti.replace(\"\", None)\n",
    "kurti = kurti.replace(\"Others\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ef5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Imputing missing values for: fit_type\n",
      "✅ Filled 142 missing values for 'fit_type'\n",
      "\n",
      "🔍 Imputing missing values for: size_range\n",
      "✅ Filled 142 missing values for 'size_range'\n",
      "\n",
      "🔍 Imputing missing values for: style\n",
      "✅ Filled 7 missing values for 'style'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_color\n",
      "✅ Filled 139 missing values for 'shoe_color'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_style\n",
      "✅ Filled 139 missing values for 'shoe_style'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define input features and target columns to fill\n",
    "features = ['product_type', 'style', 'fabric_top', 'color', 'occasion', 'work_details', 'Gender']\n",
    "targets = ['fit_type', 'size_range', 'style', 'shoe_color', 'shoe_style']\n",
    "\n",
    "# Combine all relevant columns\n",
    "all_columns = list(set(features + targets))\n",
    "df_encoded = kurti[all_columns].copy()\n",
    "\n",
    "# Label encode all columns\n",
    "label_encoders = {}\n",
    "for col in all_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Loop through each target column\n",
    "for target in targets:\n",
    "    print(f\"\\n🔍 Imputing missing values for: {target}\")\n",
    "\n",
    "    mask_missing = kurti[target].isna()\n",
    "    if mask_missing.sum() == 0:\n",
    "        print(f\"✅ No missing values in {target}\")\n",
    "        continue\n",
    "\n",
    "    # Split train and test\n",
    "    train = df_encoded[~mask_missing]\n",
    "    test = df_encoded[mask_missing]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]  \n",
    "    X_test = test[features]\n",
    "\n",
    "    if not X_test.empty:\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred_encoded = clf.predict(X_test)\n",
    "        pred_decoded = label_encoders[target].inverse_transform(pred_encoded)\n",
    "\n",
    "        # Fill predictions into original DataFrame\n",
    "        kurti.loc[mask_missing, target] = pred_decoded\n",
    "        print(f\"✅ Filled {len(pred_decoded)} missing values for '{target}'\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped '{target}' — no data to predict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "535887f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurti.drop(columns=\"size_range\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "<form action=\"/login\" method=\"post\">\n",
    "  <input type=\"email\" name=\"email\" required>\n",
    "  <input type=\"password\" name=\"password\" required>\n",
    "  <button type=\"submit\">Login</button>\n",
    "</form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aefcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "{% for item in recommendations %}\n",
    "  <div class=\"item-card\">\n",
    "    <img src=\"{{ item.Image_URL_src }}\">\n",
    "    <h4>{{ item.product_name }}</h4>\n",
    "  </div>\n",
    "{% endfor %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499dc70",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f291daf",
   "metadata": {},
   "source": [
    "# **Douti Kurta**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d844fc0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75f9425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta = pd.read_csv(\"../data/Dataset Files/Lang_Chain-douti-kurta.csv\")\n",
    "douti_kurta['categorize_outfit'] = douti_kurta['product_name'].apply(categorize_outfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fd7c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta = douti_kurta.reset_index(drop=True)\n",
    "douti_kurta.drop(columns = [\"Unnamed: 0\", \"web-scraper-order\", \"package_contents\"], inplace = True)\n",
    "douti_kurta[\"package_content\"] = \"Douti Kurta\"\n",
    "douti_kurta[\"Gender\"] = \"Male\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c35e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_work_details(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    \n",
    "    value = value.lower()\n",
    "\n",
    "    if 'plain' in value:\n",
    "        return 'Plain'\n",
    "    elif 'printed' in value or 'print' in value:\n",
    "        return 'Printed'\n",
    "    elif 'thread' in value or 'resham' in value:\n",
    "        return 'Thread/Resham Work'\n",
    "    elif 'zari' in value:\n",
    "        return 'Zari Work'\n",
    "    elif 'lace' in value or 'mirror' in value:\n",
    "        return 'Lace/Mirror Work'\n",
    "    elif 'sequins' in value or 'stone' in value or 'beads' in value or 'dabka' in value or 'cutdana' in value:\n",
    "        return 'Sequins/Stone Work'\n",
    "    elif 'woven' in value or 'weaved' in value:\n",
    "        return 'Woven'\n",
    "    elif 'embroider' in value:\n",
    "        return 'Embroidery'\n",
    "    else:\n",
    "        return 'Others'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3ae228e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta['work_details'] = douti_kurta['work_details'].apply(categorize_work_details)\n",
    "# Step 1: Get value counts\n",
    "value_counts = douti_kurta['work_details'].value_counts()\n",
    "\n",
    "# Step 2: Filter out categories with less than 6 counts\n",
    "valid_categories = value_counts[value_counts > 6].index\n",
    "\n",
    "# Step 3: Keep only rows where the category is in valid list\n",
    "douti_kurta = douti_kurta[douti_kurta['work_details'].isin(valid_categories)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fa6323d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_type\n",
       "Kurta Pajama     111\n",
       "Salwar Kameez     54\n",
       "Trouser Suit      53\n",
       "Kurta Dhoti       15\n",
       "Kurta              9\n",
       "Sherwani           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "douti_kurta[\"product_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe68e9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\1221338243.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Kurta Dhoti' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Dhoti\", case=False, na=False), \"Product\"] = \"Kurta Dhoti\"\n"
     ]
    }
   ],
   "source": [
    "douti_kurta[\"Product\"] = np.nan  \n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Dhoti\", case=False, na=False), \"Product\"] = \"Kurta Dhoti\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Kurta Pajama\", case=False, na=False), \"Product\"] = \"Kurta Pajama\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Men Kurta\", case=False, na=False), \"Product\"] = \"Kurta Pajama\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Kameez\", case=False, na=False), \"Product\"] = \"Salwar Kameez\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Suit\", case=False, na=False), \"Product\"] = \"Trouser Suit\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Sherwani\", case=False, na=False), \"Product\"] = \"Sherwani\"\n",
    "douti_kurta.loc[douti_kurta[\"product_name\"].str.contains(\"Coat\", case=False, na=False), \"Product\"] = \"Trouser Suit\"\n",
    "douti_kurta = douti_kurta[douti_kurta[\"Product\"] != \"Trouser Suit\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e70bf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define style mapping\n",
    "style_mapping = {\n",
    "    'Traditional': 'Traditional',\n",
    "    'Angrakha': 'Traditional',\n",
    "    'Festival': 'Traditional',\n",
    "\n",
    "    'Straight Cut': 'Contemporary',\n",
    "    'Indo-Western': 'Contemporary',\n",
    "    'Side Slit': 'Contemporary',\n",
    "    'Contemporary': 'Contemporary',\n",
    "    'Asymmetric': 'Contemporary',\n",
    "    'Front Slit': 'Contemporary',\n",
    "    'A Line': 'Contemporary',\n",
    "    \n",
    "    'Jacket Style': 'Fancy',\n",
    "    'Achkan Sherwani': 'Fancy',\n",
    "    'Party Wear': 'Fancy',\n",
    "\n",
    "    'Wedding': 'Heavy Work',\n",
    "    'Wedding Wear': 'Heavy Work',    \n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "douti_kurta[\"style\"] = douti_kurta[\"style\"].map(style_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "01d02392",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta['season'] = douti_kurta.apply(infer_season, axis=1)\n",
    "douti_kurta.drop(columns = \"product_type\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a4a7be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta[douti_kurta[\"season\"]==\"Unknown\"]\n",
    "douti_kurta.loc[douti_kurta[\"season\"]==\"Unknown\", \"season\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "21e4af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_mapping = {\n",
    "    # --- Silk and blends ---\n",
    "    'Silk': 'Silk-based',\n",
    "    'Dupion Silk-based': 'Silk',\n",
    "    'Cotton Silk': 'Silk-based',\n",
    "    'Art Silk': 'Silk-based',\n",
    "    'Jacquard': 'Silk-based',\n",
    "    'Brocade': 'Silk-based',\n",
    "\n",
    "    # --- Cotton ---\n",
    "    'Cotton': 'Cotton-based',\n",
    "\n",
    "    # --- Synthetic or Others ---\n",
    "    'Rayon': 'Synthetic',\n",
    "    'Satin': 'Synthetic',\n",
    "    'Georgette': 'Synthetic',\n",
    "    'Velvet': 'Synthetic'\n",
    "}\n",
    "douti_kurta[\"fabric_top\"] = douti_kurta[\"fabric_top\"].map(fabric_mapping)\n",
    "douti_kurta.drop(columns=[\"fabric_bottom\", \"package_content\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d973b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta[['fit_type', 'size_range']] = douti_kurta['fit'].apply(extract_fit_columns)\n",
    "douti_kurta.drop(columns=[\"fit\", \"Style\", \"worn_by\",\"Festival \"], inplace= True)\n",
    "douti_kurta['occasion'] = douti_kurta['occasion'].apply(categorize_occasion)\n",
    "douti_kurta.loc[douti_kurta[\"occasion\"]==\"Other\", \"occasion\"] = \"Party/Festive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7376f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta.loc[douti_kurta[\"main_category\"]==\"Men's Ethnic Wear\",\"main_category\"] = \"Indian Cloth\"\n",
    "douti_kurta.loc[(douti_kurta[\"main_category\"]==\"Men\") & (douti_kurta[\"Product\"]==\"Kurta Dhoti\"), \"main_category\"] = \"Indian Cloth\"\n",
    "douti_kurta.loc[(douti_kurta[\"main_category\"]==\"Pakistani Cloth\") & (douti_kurta[\"Product\"]==\"Kurta Pajama\"), \"main_category\"] = \"Men\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "35d865bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\1328886705.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  douti_kurta[\"fabric_top\"].fillna(\"Silk-based\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "douti_kurta = douti_kurta.replace(\"Unknown\", None)\n",
    "douti_kurta = douti_kurta.replace(\"\", None)\n",
    "douti_kurta = douti_kurta.replace(\"Others\", None)\n",
    "douti_kurta[\"fabric_top\"].fillna(\"Silk-based\", inplace=True)\n",
    "douti_kurta.drop(columns = \"size_range\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd3b815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Imputing missing values for: fit_type\n",
      "✅ Filled 108 missing values for 'fit_type'\n",
      "\n",
      "🔍 Imputing missing values for: season\n",
      "✅ Filled 17 missing values for 'season'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_color\n",
      "✅ Filled 99 missing values for 'shoe_color'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_style\n",
      "✅ Filled 99 missing values for 'shoe_style'\n"
     ]
    }
   ],
   "source": [
    "# Define input features and target columns to fill\n",
    "features = ['Product', 'style', 'fabric_top', 'color', 'occasion', 'work_details', 'Gender']\n",
    "targets = ['fit_type', 'season', 'shoe_color', 'shoe_style']\n",
    "\n",
    "# Combine all relevant columns\n",
    "all_columns = list(set(features + targets))\n",
    "df_encoded = douti_kurta[all_columns].copy()\n",
    "\n",
    "# Label encode all columns\n",
    "label_encoders = {}\n",
    "for col in all_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Loop through each target column\n",
    "for target in targets:\n",
    "    print(f\"\\n🔍 Imputing missing values for: {target}\")\n",
    "\n",
    "    mask_missing = douti_kurta[target].isna()\n",
    "    if mask_missing.sum() == 0:\n",
    "        print(f\"✅ No missing values in {target}\")\n",
    "        continue\n",
    "\n",
    "    # Split train and test\n",
    "    train = df_encoded[~mask_missing]\n",
    "    test = df_encoded[mask_missing]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]  \n",
    "    X_test = test[features]\n",
    "\n",
    "    if not X_test.empty:\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred_encoded = clf.predict(X_test)\n",
    "        pred_decoded = label_encoders[target].inverse_transform(pred_encoded)\n",
    "\n",
    "        # Fill predictions into original DataFrame\n",
    "        douti_kurta.loc[mask_missing, target] = pred_decoded\n",
    "        print(f\"✅ Filled {len(pred_decoded)} missing values for '{target}'\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped '{target}' — no data to predict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5e746fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta.rename(columns={\"Product\": \"product_type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "154a449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\1279477395.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  douti_kurta[\"main_category\"].replace('Men',\"Men's Ethnic Wear\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "douti_kurta[\"main_category\"].replace('Men',\"Men's Ethnic Wear\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de7197",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c8b2e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anarkali_suit = pd.read_csv(\"../data/Dataset Files/Lang_Chain-Anarkali-suit.csv\")\n",
    "Anarkali_suit = Anarkali_suit.reset_index(drop=True)\n",
    "Anarkali_suit.drop(columns = [\"Unnamed: 0\", \"web-scraper-order\", \"package_contents\"], inplace = True)\n",
    "Anarkali_suit[\"package_content\"] = \"Anarkali suit\"\n",
    "Anarkali_suit[\"Gender\"] = \"Female\"\n",
    "Anarkali_suit['categorize_outfit'] = Anarkali_suit['product_name'].apply(categorize_outfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "454a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First fill NaNs\n",
    "Anarkali_suit['work_details'] = Anarkali_suit['work_details'].fillna(\"Plain\")\n",
    "\n",
    "# Categorization function\n",
    "def categorize_simplified_work(value):\n",
    "    v = str(value).lower()\n",
    "\n",
    "    # Priority 1: Printed wins even if mixed\n",
    "    if any(word in v for word in ['print', 'printed', 'digital', 'dupatta']):\n",
    "        return 'Printed'\n",
    "    \n",
    "    # Priority 2: Embroidered\n",
    "    elif any(word in v for word in ['zari', 'thread', 'resham', 'embroidery', 'embroidered', 'aari', 'zardosi', 'gota', 'dori']):\n",
    "        return 'Embroidered Work'\n",
    "    \n",
    "    # Priority 3: Embellishment\n",
    "    elif any(word in v for word in ['mirror', 'stone', 'beads', 'sequins', 'cutdana', 'dabka', 'pearl', 'swarovski', 'lace', 'kundan', 'zircon']):\n",
    "        return 'Embellished Work'\n",
    "    \n",
    "    # Fallback\n",
    "    else:\n",
    "        return 'Plain / Others'\n",
    "\n",
    "# Apply the function\n",
    "Anarkali_suit['work_details'] = Anarkali_suit['work_details'].apply(categorize_simplified_work)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "26754615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\3208936190.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Anarkali_suit[\"fabric_top\"].fillna(Anarkali_suit[\"fabric_bottom\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "Anarkali_suit[\"fabric_top\"].fillna(Anarkali_suit[\"fabric_bottom\"], inplace=True)\n",
    "# Apply conditions\n",
    "Anarkali_suit.loc[Anarkali_suit[\"product_name\"].str.contains(\"Dupatta\", case=False, na=False), \"main_category\"] = \"Pakistani Cloth\"\n",
    "Anarkali_suit.loc[Anarkali_suit[\"product_name\"].str.contains(\"Pakistani\", case=False, na=False), \"main_category\"] = \"Pakistani Cloth\"\n",
    "Anarkali_suit.loc[Anarkali_suit[\"product_name\"].str.contains(\"Trouser Suit\", case=False, na=False), \"main_category\"] = \"Pakistani Cloth\"\n",
    "Anarkali_suit.loc[Anarkali_suit[\"main_category\"].str.contains(\"Indian Cloth\", case=False, na=False), \"main_category\"] = \"Women\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b302e2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\1616480347.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Anarkali_suit[\"main_category\"].replace('Women',\"Women's Ethnic Wear\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "Anarkali_suit[\"style\"] = Anarkali_suit[\"style\"].map(style_mapping)\n",
    "Anarkali_suit[['fit_type', 'size_range']] = Anarkali_suit['fit'].apply(extract_fit_columns)\n",
    "Anarkali_suit.drop(columns=[\"fit\",\"worn_by\", \"size_range\",\"package_content\",\"Package Content\"], inplace= True)\n",
    "Anarkali_suit['occasion'] = Anarkali_suit['occasion'].apply(categorize_occasion)\n",
    "Anarkali_suit[\"main_category\"].replace('Women',\"Women's Ethnic Wear\", inplace=True)\n",
    "\n",
    "fabric_mapping = {\n",
    "    'Georgette': 'Georgette',\n",
    "    'Faux Georgette': 'Georgette',\n",
    "    'Satin Georgette': 'Georgette',\n",
    "\n",
    "    'Net': 'Net',\n",
    "    'Soft Net': 'Net',\n",
    "\n",
    "    'Silk': 'Silk',\n",
    "    'Soft Silk': 'Silk',\n",
    "    'Art Silk': 'Silk',\n",
    "    'Poly Silk': 'Silk',\n",
    "    'Cotton Silk': 'Silk',\n",
    "    'Florida Silk': 'Silk',\n",
    "    'Upada Silk': 'Silk',\n",
    "    'Taffeta Silk': 'Silk',\n",
    "    'Two Tone Taffeta Silk': 'Silk',\n",
    "    'Taffeta': 'Silk',\n",
    "    'Bangalori Silk': 'Silk',\n",
    "    'Banglori Silk': 'Silk',\n",
    "    'Dupion Silk': 'Silk',\n",
    "    'Dupion': 'Silk',\n",
    "    'Dupian Silk': 'Silk',\n",
    "    'Chanderi Silk': 'Silk',\n",
    "\n",
    "    'Velvet': 'Velvet',\n",
    "\n",
    "    'Organza': 'Organza',\n",
    "    'Chiffon': 'Chiffon',\n",
    "    'Crepe': 'Crepe',\n",
    "    'Cotton': 'Cotton',\n",
    "    'Chanderi': 'Chanderi',\n",
    "    'Satin': 'Satin',\n",
    "    'Muslin': 'Muslin',\n",
    "    'Brocade': 'Brocade',\n",
    "    'Viscose': 'Viscose'\n",
    "}\n",
    "\n",
    "# Apply the mapping to your DataFrame\n",
    "Anarkali_suit['fabric_top'] = Anarkali_suit['fabric_top'].map(fabric_mapping)\n",
    "\n",
    "Anarkali_suit.drop(columns=\"fabric_bottom\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2bba05de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Imputing missing values for: style\n",
      "✅ Filled 256 missing values for 'style'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_color\n",
      "✅ Filled 363 missing values for 'shoe_color'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_style\n",
      "✅ Filled 363 missing values for 'shoe_style'\n",
      "\n",
      "🔍 Imputing missing values for: fit_type\n",
      "✅ Filled 436 missing values for 'fit_type'\n",
      "\n",
      "🔍 Imputing missing values for: season\n",
      "✅ Filled 1 missing values for 'season'\n",
      "\n",
      "🔍 Imputing missing values for: fabric_top\n",
      "✅ Filled 1 missing values for 'fabric_top'\n"
     ]
    }
   ],
   "source": [
    "Anarkali_suit = Anarkali_suit.replace(\"Unknown\", None)\n",
    "Anarkali_suit = Anarkali_suit.replace(\"\", None)\n",
    "Anarkali_suit = Anarkali_suit.replace(\"Others\", None)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define input features and target columns to fill\n",
    "features = ['product_type', 'style', 'fabric_top', 'color', 'occasion', 'work_details', 'Gender']\n",
    "targets = ['style','shoe_color', 'shoe_style', 'fit_type', 'season', 'fabric_top']\n",
    "\n",
    "# Combine all relevant columns\n",
    "all_columns = list(set(features + targets))\n",
    "df_encoded = Anarkali_suit[all_columns].copy()\n",
    "\n",
    "# Label encode all columns\n",
    "label_encoders = {}\n",
    "for col in all_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Loop through each target column\n",
    "for target in targets:\n",
    "    print(f\"\\n🔍 Imputing missing values for: {target}\")\n",
    "\n",
    "    mask_missing = Anarkali_suit[target].isna()\n",
    "    if mask_missing.sum() == 0:\n",
    "        print(f\"✅ No missing values in {target}\")\n",
    "        continue\n",
    "\n",
    "    # Split train and test\n",
    "    train = df_encoded[~mask_missing]\n",
    "    test = df_encoded[mask_missing]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]  \n",
    "    X_test = test[features]\n",
    "\n",
    "    if not X_test.empty:\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred_encoded = clf.predict(X_test)\n",
    "        pred_decoded = label_encoders[target].inverse_transform(pred_encoded)\n",
    "\n",
    "        # Fill predictions into original DataFrame\n",
    "        Anarkali_suit.loc[mask_missing, target] = pred_decoded\n",
    "        print(f\"✅ Filled {len(pred_decoded)} missing values for '{target}'\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped '{target}' — no data to predict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a6c3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "82cfe74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.read_csv(\"../data/Dataset Files/LangChain_first_half.csv\")\n",
    "Dataset = Dataset.reset_index(drop=True)\n",
    "\n",
    "Dataset.drop(columns = [\"Unnamed: 0\", \"package_contents\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d557423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohaib malik\\AppData\\Local\\Temp\\ipykernel_22232\\4065872392.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Dataset[\"fabric_top\"].fillna(Dataset[\"fabric_bottom\"], inplace= True)\n"
     ]
    }
   ],
   "source": [
    "Dataset[\"fabric_top\"].fillna(Dataset[\"fabric_bottom\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fb3b2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to assign category + gender\n",
    "def assign_category_and_gender(keyword, worn_by_val, category_val, gender_val):\n",
    "    Dataset.loc[\n",
    "        (Dataset[\"product_name\"].fillna(\"\").str.contains(keyword, case=False)) &\n",
    "        (Dataset[\"worn_by\"].fillna(\"\").str.contains(worn_by_val, case=False)),\n",
    "        [\"main_category\", \"Gender\"]\n",
    "    ] = [category_val, gender_val]\n",
    "\n",
    "# Specific keyword-based rules\n",
    "assign_category_and_gender(\"Churidar\", \"Women\", \"Indian Cloth\", \"Female\")\n",
    "assign_category_and_gender(\"Churidar\", \"Men\", \"Indian Cloth\", \"Male\")\n",
    "assign_category_and_gender(\"Suit\", \"Women\", \"Pakistani Cloth\", \"Female\")\n",
    "\n",
    "# Product-specific assignments\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Sherwani\", case=False), \n",
    "    [\"main_category\", \"Gender\"]\n",
    "] = [\"Men's Ethnic Wear\", \"Male\"]\n",
    "\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Dhoti\", case=False), \n",
    "    [\"main_category\", \"Gender\"]\n",
    "] = [\"Indian Cloth\", \"Male\"]\n",
    "\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Salwar Kameez\", case=False), \n",
    "    [\"main_category\", \"Gender\"]\n",
    "] = [\"Indian Cloth\", \"Male\"]\n",
    "\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Patiala\", case=False), \n",
    "    [\"main_category\", \"Gender\"]\n",
    "] = [\"Indian Cloth\", \"Female\"]\n",
    "\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Dupatta\", case=False), \n",
    "    [\"main_category\", \"Gender\"]\n",
    "] = [\"Indian Cloth\", \"Female\"]\n",
    "\n",
    "# Assign Men’s Ethnic Wear for these styles\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Kurta Pajama\", case=False)) &\n",
    "    (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Men\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Coat Pant\", case=False)) &\n",
    "    (Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Kurta\", case=False)) &\n",
    "    (Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_type\"].fillna(\"\").str.contains(\"Sherwani\", case=False)) &\n",
    "    (Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men Sherwani\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "# Clean from misassigned values\n",
    "Dataset.loc[\n",
    "    Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men's\", case=False),\n",
    "    \"Gender\"\n",
    "] = \"Male\"\n",
    "Dataset.loc[\n",
    "    Dataset[\"main_category\"].fillna(\"\").str.contains(\"Women's\", case=False),\n",
    "    \"Gender\"\n",
    "] = \"Female\"\n",
    "\n",
    "# Additional Rules\n",
    "# Men’s Suit → Men’s Ethnic Wear\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Men's Suit\", case=False), \n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "# Anarkali (common for women)\n",
    "Dataset.loc[\n",
    "    Dataset[\"product_name\"].fillna(\"\").str.contains(\"Anarkali\", case=False) |\n",
    "    Dataset[\"style\"].fillna(\"\").str.contains(\"Anarkali\", case=False), \n",
    "    \"main_category\"\n",
    "] = \"Women's Ethnic Wear\"\n",
    "\n",
    "# If 'Men' in both product_name and worn_by\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Men\", case=False)) &\n",
    "    (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Men\", case=False)), \n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "# 'Trouser Suit' + Women → Women's Ethnic Wear\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Trouser Suit\", case=False)) &\n",
    "    (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Women\", case=False)), \n",
    "    \"main_category\"\n",
    "] = \"Women's Ethnic Wear\"\n",
    "\n",
    "# Gown, Sharara, Palazzo, Trouser, Kurti (only when worn_by is Women) → Women's Ethnic Wear\n",
    "Dataset.loc[\n",
    "    (\n",
    "        Dataset[\"product_name\"].fillna(\"\").str.contains(\"Gown\", case=False) |\n",
    "        Dataset[\"product_name\"].fillna(\"\").str.contains(\"Sharara\", case=False) |\n",
    "        Dataset[\"product_name\"].fillna(\"\").str.contains(\"Palazzo\", case=False) |\n",
    "        Dataset[\"product_name\"].fillna(\"\").str.contains(\"Trouse\", case=False) |\n",
    "        Dataset[\"product_name\"].fillna(\"\").str.contains(\"Kurti\", case=False)\n",
    "    ) &\n",
    "    (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Women\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Women's Ethnic Wear\"\n",
    "\n",
    "# Final gender cleanup from updated main_category\n",
    "Dataset.loc[\n",
    "    Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men's\", case=False),\n",
    "    \"Gender\"\n",
    "] = \"Male\"\n",
    "Dataset.loc[\n",
    "    Dataset[\"main_category\"].fillna(\"\").str.contains(\"Women's\", case=False),\n",
    "    \"Gender\"\n",
    "] = \"Female\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4e1f4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Gender from worn_by when Gender is missing\n",
    "Dataset.loc[\n",
    "    (Dataset[\"Gender\"].isna()) & (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Women\", case=False)),\n",
    "    \"Gender\"\n",
    "] = \"Female\"\n",
    "Dataset.loc[\n",
    "    (Dataset[\"Gender\"].isna()) & (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Men\", case=False)),\n",
    "    \"Gender\"\n",
    "] = \"Male\"\n",
    "Dataset.loc[(Dataset[\"web-scraper-start-url\"].fillna(\"\").str.contains(\"p=19\", case=False)) & Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Women\", case=False), [\"worn_by\", \"Gender\"]] = [\"Male\", \"Male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4ad1b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.loc[\n",
    "    (Dataset[\"web-scraper-start-url\"].fillna(\"\").str.contains(\"p=1\", case=False)) &\n",
    "    (Dataset[\"worn_by\"].fillna(\"\").str.contains(\"Women\", case=False))\n",
    "]\n",
    "Dataset.loc[(Dataset[\"product_name\"]==\"Cotton Pathani Kurta In White Colour\"), \"Gender\"] = \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4a9d6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Blue Jodhpuri\", case=False)) &\n",
    "    (Dataset[\"product_type\"].fillna(\"\").str.contains(\"Trouser Suit\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Black Jacquard Blazer\", case=False)) &\n",
    "    (Dataset[\"product_type\"].fillna(\"\").str.contains(\"Trouser Suit\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"product_name\"].fillna(\"\").str.contains(\"Men Sherwani\", case=False)) &\n",
    "    (Dataset[\"product_type\"].fillna(\"\").str.contains(\"Trouser Suit\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\"\n",
    "\n",
    "Dataset.loc[\n",
    "    (Dataset[\"main_category\"].fillna(\"\").str.contains(\"Men Sherwani\", case=False)) &\n",
    "    (Dataset[\"product_type\"].fillna(\"\").str.contains(\"Trouser Suit\", case=False)),\n",
    "    \"main_category\"\n",
    "] = \"Men's Ethnic Wear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "63cdaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset[~Dataset[\"product_type\"].str.contains(\"Hijab\", case=False, na=False)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b152ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[['fit_type', 'size_range']] = Dataset['fit'].apply(extract_fit_columns)\n",
    "Dataset.drop(columns=[\"fit\", \"worn_by\", \"size_range\", \"fabric_bottom\"], inplace= True)\n",
    "Dataset['occasion'] = Dataset['occasion'].apply(categorize_occasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3f09df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define full fabric category lists\n",
    "cotton_based = ['Cotton', 'Cotton Silk', 'Poly Cotton', 'Linen']\n",
    "silk_based = [\n",
    "    'Silk', 'Dupion Silk', 'Art Silk', 'Silk Blend', 'Banarasi Silk', \n",
    "    'Banglori Silk', 'Jacquard Silk', 'Raw Silk', 'Brocade'\n",
    "]\n",
    "synthetic = [\n",
    "    'Georgette', 'Net', 'Velvet', 'Rayon', 'Organza', 'Viscose', 'Jacquard'\n",
    "]\n",
    "\n",
    "# Categorization function\n",
    "def categorize_fabric(fabric):\n",
    "    if fabric in cotton_based:\n",
    "        return 'Cotton-based'\n",
    "    elif fabric in silk_based:\n",
    "        return 'Silk-based'\n",
    "    elif fabric in synthetic:\n",
    "        return 'Synthetic'\n",
    "    else:\n",
    "        return   None  \n",
    "\n",
    "# Apply the function\n",
    "Dataset['fabric_top'] = Dataset['fabric_top'].apply(categorize_fabric)\n",
    "Dataset['season'] = Dataset.apply(infer_season, axis=1)\n",
    "Dataset = Dataset[~Dataset['product_name'].str.contains('Dupatta', case=False, na=False)].reset_index(drop=True)\n",
    "Dataset['categorize_outfit'] = Dataset['product_name'].apply(categorize_outfit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c671f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "def correct_gender(url, current_gender):\n",
    "    if 'men/' in url:\n",
    "        return 'Male'\n",
    "    elif 'womens/' in url:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return current_gender  \n",
    "\n",
    "# Apply the correction\n",
    "Dataset['Gender'] = Dataset.apply(\n",
    "    lambda row: correct_gender(row['web-scraper-start-url'], row['Gender']), \n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98761aa",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c6b90a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.replace(\"Unknown\", None)\n",
    "Dataset = Dataset.replace(\"\", None)\n",
    "Dataset = Dataset.replace(\"Others\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "099a77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Imputing missing values for: fit_type\n",
      "✅ Filled 1125 missing values for 'fit_type'\n",
      "\n",
      "🔍 Imputing missing values for: season\n",
      "✅ Filled 499 missing values for 'season'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_color\n",
      "✅ Filled 917 missing values for 'shoe_color'\n",
      "\n",
      "🔍 Imputing missing values for: shoe_style\n",
      "✅ Filled 918 missing values for 'shoe_style'\n",
      "\n",
      "🔍 Imputing missing values for: work_details\n",
      "✅ Filled 125 missing values for 'work_details'\n",
      "\n",
      "🔍 Imputing missing values for: season\n",
      "✅ No missing values in season\n",
      "\n",
      "🔍 Imputing missing values for: occasion\n",
      "✅ Filled 4 missing values for 'occasion'\n",
      "\n",
      "🔍 Imputing missing values for: style\n",
      "✅ Filled 17 missing values for 'style'\n",
      "\n",
      "🔍 Imputing missing values for: fabric_top\n",
      "✅ Filled 274 missing values for 'fabric_top'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define input features and target columns to fill\n",
    "features = ['color', 'Gender']\n",
    "targets = ['fit_type', 'season', 'shoe_color', 'shoe_style', 'work_details', 'season','occasion',  'style', 'fabric_top']\n",
    "\n",
    "# Combine all relevant columns\n",
    "all_columns = list(set(features + targets))\n",
    "df_encoded = Dataset[all_columns].copy()\n",
    "\n",
    "# Label encode all columns\n",
    "label_encoders = {}\n",
    "for col in all_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Loop through each target column\n",
    "for target in targets:\n",
    "    print(f\"\\n🔍 Imputing missing values for: {target}\")\n",
    "\n",
    "    mask_missing = Dataset[target].isna()\n",
    "    if mask_missing.sum() == 0:\n",
    "        print(f\"✅ No missing values in {target}\")\n",
    "        continue\n",
    "\n",
    "    # Split train and test\n",
    "    train = df_encoded[~mask_missing]\n",
    "    test = df_encoded[mask_missing]\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]  \n",
    "    X_test = test[features]\n",
    "\n",
    "    if not X_test.empty:\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred_encoded = clf.predict(X_test)\n",
    "        pred_decoded = label_encoders[target].inverse_transform(pred_encoded)\n",
    "\n",
    "        # Fill predictions into original DataFrame\n",
    "        Dataset.loc[mask_missing, target] = pred_decoded\n",
    "        print(f\"✅ Filled {len(pred_decoded)} missing values for '{target}'\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped '{target}' — no data to predict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9716017",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "552bbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "douti_kurta.rename(columns={\"package_contents\": \"package_contents\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d9d1863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(Dataset.columns)\\nprint(Anarkali_suit.columns)\\nprint(kurti.columns)\\nprint(douti_kurta.columns)'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(Dataset.columns)\n",
    "print(Anarkali_suit.columns)\n",
    "print(kurti.columns)\n",
    "print(douti_kurta.columns)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5b446e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [\n",
    "    'web-scraper-start-url', 'Products-href', 'Image URL-src',\n",
    "    'product_name', 'main_category', 'product_type', 'style', 'fabric_top',\n",
    "    'color', 'occasion', 'season', 'price_pkr', 'discount', 'work_details',\n",
    "    'shoe_color', 'shoe_style', 'Gender', 'fit_type', 'categorize_outfit'\n",
    "]\n",
    "dfs = [Dataset, kurti, douti_kurta, Anarkali_suit]\n",
    "dfs = [df.reindex(columns=final_columns) for df in dfs]\n",
    "final_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c55b0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates(subset=\"product_name\")\n",
    "final_df.drop(columns=\"product_type\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "196c767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_mapping = {\n",
    "    # 🟩 Traditional styles\n",
    "    'Traditional': 'Traditional',\n",
    "    'Churidar': 'Traditional',\n",
    "    'Churidar Pajami Style': 'Traditional',\n",
    "    'Angrakha': 'Traditional',\n",
    "    'Jodhpuri': 'Traditional',\n",
    "    'Bandhej': 'Traditional',\n",
    "    'Dhoti': 'Traditional',\n",
    "    'Bandhgala': 'Traditional',\n",
    "\n",
    "    # 🟦 Contemporary / Modern cuts\n",
    "    'Straight Cut': 'Contemporary',\n",
    "    'Contemporary': 'Contemporary',\n",
    "    'Indo-Western': 'Contemporary',\n",
    "    'Indo Western': 'Contemporary',\n",
    "    'A Line': 'Contemporary',\n",
    "    'Assymetrical': 'Contemporary',\n",
    "    'Asymmetric': 'Contemporary',\n",
    "    'Side Slit': 'Contemporary',\n",
    "\n",
    "    # 🟨 Fancy styles (occasion wear, layered or tailored)\n",
    "    'Jacket Style': 'Fancy',\n",
    "    'Achkan': 'Fancy',\n",
    "    'Achkan Sherwani': 'Fancy',\n",
    "    'Party Wear': 'Fancy',\n",
    "    'Shimmer': 'Fancy',\n",
    "    'Light Weight': 'Fancy',\n",
    "\n",
    "    # 🟥 Heavy, bridal, or ceremonial\n",
    "    'Wedding Wear': 'Heavy Work',\n",
    "    'Wedding': 'Heavy Work',\n",
    "    'Heavy Work': 'Heavy Work',\n",
    "    'Broad Border': 'Heavy Work',\n",
    "\n",
    "    # 🟪 Embroidery-related\n",
    "    'Embroidered': 'Embroidered',\n",
    "\n",
    "    # 🟧 Printed / Patterns\n",
    "    'Printed': 'Printed',\n",
    "    'Floral': 'Printed',\n",
    "}\n",
    "final_df['Category Style'] = final_df['style'].map(style_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d9240ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_mapping = {\n",
    "    'Silk-based': 'Silk',\n",
    "    'Silk': 'Silk',\n",
    "    'Cotton-based': 'Cotton',\n",
    "    'Cotton': 'Cotton',\n",
    "    'Synthetic': 'Synthetic',\n",
    "    'Georgette': 'Georgette',\n",
    "    'Net': 'Net',\n",
    "    'Velvet': 'Velvet',\n",
    "    'Chiffon': 'Sheer Fabric',\n",
    "    'Organza': 'Sheer Fabric',\n",
    "    'Crepe': 'Crepe',\n",
    "    'Chanderi': 'Traditional Weave',\n",
    "    'Satin': 'Silk Blend',\n",
    "    'Viscose': 'Silk Blend',\n",
    "    'Muslin': 'Cotton',\n",
    "    'Brocade': 'Silk Blend'\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "final_df['fabric'] = final_df['fabric_top'].map(fabric_mapping)\n",
    "final_df.drop(columns = [\"fabric_top\", \"style\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db46e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Wardrobe Assistant.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wardrobe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
